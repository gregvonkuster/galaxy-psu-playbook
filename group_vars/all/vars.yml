---

# Python 3 support
pip_virtualenv_command: /usr/bin/python3 -m venv
certbot_virtualenv_package_name: python3-venv
#pip_package: python3-pip

all_packages:
  - acl
  - bzip2
  - git
  - make
  - tar
  - python3-venv

# Convenience variables
corral_root: /corral/main/projects/Galaxy-PSU

# Slurm is installed on all hosts
slurm_munge_key: files/slurm/munge.key
slurm_create_user: yes
slurm_user:
  name: slurm
  group: slurm
  uid: 800
  gid: 800
  home: /home/slurm
  shell: /bin/bash
  system: true

slurm_config:
  ControlMachine: "{{ groups.slurmservers[0].split('.')[0] }}"
  #ControlAddr: 
  SelectType: select/cons_res
  SelectTypeParameters: CR_CPU_Memory
  SlurmctldDebug: 4
  SlurmdDebug: 4

  SlurmdParameters: config_overrides

  ReturnToService: 1
  RebootProgram: /usr/sbin/reboot

  JobAcctGatherType: jobacct_gather/cgroup
  JobAcctGatherFrequency: task=15
  ProctrackType: proctrack/cgroup
  TaskPlugin: task/cgroup

# Weight nodes such that when they are in the same partition, the standard nodes are preferred over the big memory nodes

slurm_nodes:
  - name: galaxy-psu-jobs1
    CPUs: 8
    RealMemory: 32089
    Weight: 0
  - name: galaxy-psu-bigjobs1
    CPUs: 8
    RealMemory: 257736
    Weight: 10

# Prioritize jobs such that jobs in the bigmem partition will get priority access to the (shared) big memory nodes

slurm_partitions:
  - name: normal
    Default: YES
    Nodes: galaxy-psu-jobs1,galaxy-psu-bigjobs1
    State: UP
    DefMemPerCPU: 4000
    PriorityTier: 0
  - name: bigmem
    Nodes: galaxy-psu-bigjobs1
    State: UP
    DefMemPerCPU: 32216
    PriorityTier: 10

slurm_cgroup_config:
  CgroupAutomount: yes
  ConstrainCores: yes
  ConstrainRAMSpace: yes
  ConstrainSwapSpace: yes
